# -*- coding: utf-8 -*-
"""XGBoost_multiclass_classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cs8kR-ZbQVhZOyviAeH0obDr_T1uFBm7

1. Προεπεξεργασία Δεδομένων
Διαβάζει ένα CSV αρχείο (Multiclassification_Database.csv).
Αφαιρεί στήλες που δεν είναι χαρακτηριστικά (Timestamp, DRB.RlcDelayUl).
Διαχωρίζει χαρακτηριστικά X και ετικέτες y.

2. Διαχωρισμός Εκπαίδευσης/Ελέγχου
Χρησιμοποιεί train_test_split με stratify=y για ισορροπημένες κλάσεις.

3. Pipeline με XGBoost
Δημιουργεί pipeline με:
StandardScaler για κανονικοποίηση χαρακτηριστικών.
XGBClassifier με multi:softprob για πολυταξινόμηση.
Ορίζει grid παραμέτρων για GridSearchCV.

4. Εκπαίδευση με GridSearchCV
Εκτελεί 5-fold cross-validation με f1_macro ως metric.
Επιλέγει το καλύτερο μοντέλο (best).

5. Αξιολόγηση Μοντέλου
Υπολογίζει:
Accuracy, Precision, Recall, F1 (macro).
Αναλυτικό classification_report.
Normalized confusion matrix.
ROC καμπύλες για κάθε κλάση (OvR).
Precision–Recall καμπύλες.

6. Feature Importance
Οπτικοποιεί τη σημασία χαρακτηριστικών με xgb.plot_importance.

7. Αποθήκευση Αποτελεσμάτων
Αποθηκεύει:
Το pipeline (xgb_best_pipeline.pkl).
CSV με metrics ανά κλάση και συνοπτικά.
Εικόνες (confusion matrix, ROC, PR, feature importance) σε PNG/PDF.
"""

from google.colab import drive
drive.mount('/content/drive')

# -*- coding: utf-8 -*-
"""XGBoost_multiclass_classifier.ipynb — minimal, version-safe fixes"""

import pandas as pd
import numpy as np
from pathlib import Path

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline                      # FIX: add Pipeline
from sklearn.metrics import (
    classification_report, confusion_matrix,
    accuracy_score, precision_score, recall_score, f1_score,
    roc_curve, auc, precision_recall_curve, average_precision_score
)
from sklearn.preprocessing import label_binarize

import xgboost as xgb
import joblib
import seaborn as sns
import matplotlib.pyplot as plt

# 1) Load & drop non-feature columns (as before)
csv_path = Path("Multiclassification_Database.csv")
df = pd.read_csv(csv_path)
df = df.drop(columns=['Timestamp', 'DRB.RlcDelayUl'], errors="ignore")

# Separate features/labels
X = df.drop(columns=['Label'])
y = df['Label']

# 2) Split (scaling will happen inside CV via Pipeline)              # FIX: no pre-fit scaler
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.3, random_state=42
)

# 3) Model inside a Pipeline to avoid leakage                        # FIX
xgb_clf = xgb.XGBClassifier(
    objective='multi:softprob',
    # num_class optional; XGB infers from labels
    use_label_encoder=False,
    eval_metric='mlogloss',
    n_jobs=-1,
    random_state=42
)

pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', xgb_clf)
])

# Your original grid, prefixed with 'clf__'                          # FIX
param_grid = {
    'clf__n_estimators':     [100, 200],
    'clf__max_depth':        [4, 6, 8],
    'clf__learning_rate':    [0.01, 0.1],
    'clf__subsample':        [0.6, 0.8],
    'clf__colsample_bytree': [0.6, 0.8],
}

# 4) Grid Search (same CV=5, small grid → quick)
grid = GridSearchCV(pipe, param_grid, cv=5, scoring='f1_macro', n_jobs=-1, verbose=1)
grid.fit(X_train, y_train)
best = grid.best_estimator_

# Predict
y_pred = best.predict(X_test)
y_pred_prob = best.predict_proba(X_test)  # column order matches best.named_steps['clf'].classes_

# Metrics
test_accuracy = accuracy_score(y_test, y_pred)
test_precision = precision_score(y_test, y_pred, average='macro', zero_division=0)
test_recall = recall_score(y_test, y_pred, average='macro', zero_division=0)
test_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)

print("Accuracy:", test_accuracy)
print("Precision (macro):", test_precision)
print("Recall (macro):", test_recall)
print("F1 Score (macro):", test_f1)
print("\nClassification Report:")
print(classification_report(y_test, y_pred, digits=4, zero_division=0))

# --- Safer class order for plots (no hardcoding) ------------------- # FIX
classes_order = list(best.named_steps['clf'].classes_)  # consistent with predict_proba columns
# If your labels are 0,1,2 and you want pretty names:
name_map = {0: 'Gaming', 1: 'TikTok', 2: 'Browsing'}
tick_names = [name_map.get(c, str(c)) for c in classes_order]

# Confusion Matrix (normalized)
cm = confusion_matrix(y_test, y_pred, labels=classes_order)
cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)

plt.figure(figsize=(7,6))
sns.heatmap(cm_normalized, annot=True, fmt=".2f", cmap="Blues",
            xticklabels=tick_names, yticklabels=tick_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Normalized Confusion Matrix')
plt.tight_layout()
plt.show()

# Multi-class ROC (OvR) using the same class order                   # FIX
y_true_bin = label_binarize(y_test, classes=classes_order)
fpr, tpr, roc_auc = {}, {}, {}
plt.figure(figsize=(8,6))
for i, c in enumerate(classes_order):
    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
    plt.plot(fpr[i], tpr[i], label=f'{name_map.get(c, c)} (AUC={roc_auc[i]:.2f})')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-class ROC Curves')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Precision-Recall curves (same order)
plt.figure(figsize=(8,6))
for i, c in enumerate(classes_order):
    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])
    ap = average_precision_score(y_true_bin[:, i], y_pred_prob[:, i])
    plt.plot(recall, precision, label=f'{name_map.get(c, c)} (AP={ap:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curves')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 6) Feature importance (same call)
xgb.plot_importance(best.named_steps['clf'], max_num_features=15)     # FIX: access inner clf
plt.tight_layout()
plt.show()

# 7) Save artifacts (Pipeline already contains scaler + model)       # FIX
joblib.dump(best, "xgb_best_pipeline.pkl")
print("Saved: xgb_best_pipeline.pkl")

import pandas as pd
from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

class_names = ["Gaming", "Streaming", "Browsing"]  # TikTok -> Streaming

# Αναλυτικό report σε dict
report = classification_report(
    y_test, y_pred, target_names=class_names, digits=4, output_dict=True
)

# Πίνακας ανά κλάση
per_class = (
    pd.DataFrame(report)
      .T.loc[class_names, ["precision", "recall", "f1-score", "support"]]
      .rename(columns={"f1-score": "f1"})
)
per_class.index.name = "Class"

# Πίνακας σύνοψης
summary = pd.DataFrame({
    "Accuracy": [report["accuracy"]],
    "Macro P": [report["macro avg"]["precision"]],
    "Macro R": [report["macro avg"]["recall"]],
    "Macro F1": [report["macro avg"]["f1-score"]],
    "Support": [int(per_class["support"].sum())]
})

# Εκτύπωση & αποθήκευση
pd.options.display.float_format = "{:.4f}".format
print("\nPer-class metrics:\n", per_class, "\n")
print("Summary:\n", summary, "\n")

per_class.to_csv("xgb_per_class_metrics.csv")
summary.to_csv("xgb_summary_metrics.csv", index=False)

# Ανέβασε το times.ttf αν το θες 100% σε Times
from google.colab import files
import os, shutil, subprocess, matplotlib as mpl

uploaded = files.upload()  # διάλεξε times.ttf
os.makedirs("/usr/share/fonts/truetype/custom", exist_ok=True)
for name in uploaded:
    shutil.move(name, f"/usr/share/fonts/truetype/custom/{name}")

subprocess.run(["fc-cache", "-fv"], capture_output=True, text=True)
FONT_PATH = "/usr/share/fonts/truetype/custom/times.ttf"  # άλλαξέ το αν έχει άλλο όνομα

mpl.rcParams["font.family"] = "serif"
mpl.rcParams["font.serif"]  = ["Times New Roman", "Times", "Nimbus Roman", "DejaVu Serif"]
mpl.rcParams["pdf.fonttype"] = 42
mpl.rcParams["ps.fonttype"]  = 42

print("OK. Font at:", FONT_PATH)

from sklearn.metrics import confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt

# Γενικές ρυθμίσεις γραμματοσειράς για ΟΛΑ τα σχήματα του αρχείου
mpl.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman", "Times", "DejaVu Serif"],
    "axes.titlesize": 20,
    "axes.labelsize": 18,
    "xtick.labelsize": 16,
    "ytick.labelsize": 16,
    "legend.fontsize": 19,
    "pdf.fonttype": 42,
    "ps.fonttype": 42
})

# Confusion matrix (normalized by row)
labels = ["Gaming", "Streaming", "Browsing"]   # TikTok -> Streaming
cm = confusion_matrix(y_test, y_pred, labels=list(best.classes_))
cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)

fig, ax = plt.subplots(figsize=(7, 6), dpi=300)
sns.heatmap(
    cm_norm, annot=True, fmt=".2f", cmap="Blues", square=True,
    xticklabels=labels, yticklabels=labels,
    vmin=0.0, vmax=1.0, annot_kws={"size": 21}, ax=ax
)
ax.set_xlabel("Predicted")
ax.set_ylabel("True")

# Μεγαλύτερα ticks στο colorbar
cbar = ax.collections[0].colorbar
cbar.ax.tick_params(labelsize=21)

fig.tight_layout()
fig.savefig("xgb_confusion_matrix_normalized.png", dpi=300, bbox_inches="tight")
fig.savefig("xgb_confusion_matrix_normalized.pdf", bbox_inches="tight")
plt.show()

# === Precision–Recall curves (XGBoost) ===
from sklearn.preprocessing import label_binarize
from sklearn.metrics import precision_recall_curve, average_precision_score
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

# Πάρε το μοντέλο (best από GridSearch ή clf)
try:
    model = best
except NameError:
    model = clf  # αν δεν υπάρχει ούτε αυτό, άλλαξε το όνομα στο δικό σου

# Πιθανότητες & σειρά κλάσεων από το μοντέλο
proba   = model.predict_proba(X_test)        # shape: [N, n_classes]
classes = list(model.classes_)               # π.χ. [0,1,2]

# Ονόματα για παρουσίαση (TikTok -> Streaming) ΜΕ την ίδια σειρά όπως στο model.classes_
name_map = {0: "Gaming", 1: "Streaming", 2: "Browsing"}
class_names_ordered = [name_map[c] for c in classes]

# Binarize targets στη ΣΕΙΡΑ των classes του μοντέλου
Y = label_binarize(y_test, classes=classes)

# Γραμματοσειρές 21pt (Times New Roman + fallbacks)
mpl.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman", "Times", "DejaVu Serif"],
    "axes.titlesize": 21,
    "axes.labelsize": 21,
    "xtick.labelsize": 21,
    "ytick.labelsize": 21,
    "legend.fontsize": 21,
    "pdf.fonttype": 42,
    "ps.fonttype": 42
})

fig, ax = plt.subplots(figsize=(10, 6), dpi=300, constrained_layout=False)

for i, name in enumerate(class_names_ordered):
    prec, rec, _ = precision_recall_curve(Y[:, i], proba[:, i])
    ap = average_precision_score(Y[:, i], proba[:, i])
    ax.plot(rec, prec, linewidth=2, label=f"{name} (AP={ap:.2f})")

ax.set_xlabel("Recall")
ax.set_ylabel("Precision")
ax.set_xlim(0.0, 1.0)
ax.set_ylim(0.0, 1.01)
ax.grid(True, alpha=0.3)

# Legend μέσα, κάτω αριστερά και “πιο μεγάλο”
ax.legend(loc="lower left",
          frameon=True, fancybox=True, framealpha=0.95,
          borderpad=0.8, labelspacing=0.6, handlelength=3.0)

fig.tight_layout()
fig.savefig("xgb_precision_recall_curves.png", dpi=300, bbox_inches="tight")
fig.savefig("xgb_precision_recall_curves.pdf", bbox_inches="tight")
plt.show()

# === Multi-class ROC (XGBoost) ===
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

# Πάρε το μοντέλο (best από GridSearch ή clf)
try:
    model = best
except NameError:
    model = clf  # βάλε εδώ το όνομα του μοντέλου σου αν είναι διαφορετικό

# Πιθανότητες & σειρά κλάσεων
proba   = model.predict_proba(X_test)      # shape: [N, n_classes]
classes = list(model.classes_)             # π.χ. [0,1,2]

# Ονόματα για το legend με mapping IDs->ονόματα (TikTok -> Streaming)
name_map = {0: "Gaming", 1: "Streaming", 2: "Browsing"}
class_names_ordered = [name_map[c] for c in classes]

# Binarize στόχους στη ΣΕΙΡΑ των classes του μοντέλου
Y = label_binarize(y_test, classes=classes)

# Γραμματοσειρές 21pt (Times New Roman + fallbacks)
mpl.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman", "Times", "DejaVu Serif"],
    "axes.titlesize": 21,
    "axes.labelsize": 21,
    "xtick.labelsize": 21,
    "ytick.labelsize": 21,
    "legend.fontsize": 21,
    "pdf.fonttype": 42,
    "ps.fonttype": 42
})

fig, ax = plt.subplots(figsize=(10, 6), dpi=300, constrained_layout=False)

# Καμπύλες ανά κλάση
for i, name in enumerate(class_names_ordered):
    fpr, tpr, _ = roc_curve(Y[:, i], proba[:, i])
    roc_auc = auc(fpr, tpr)
    ax.plot(fpr, tpr, linewidth=2, label=f"{name} (AUC={roc_auc:.2f})")

# Διαγώνιος τυχαιότητας
ax.plot([0, 1], [0, 1], linestyle="--", linewidth=1.5, color="black")

ax.set_xlabel("False Positive Rate")
ax.set_ylabel("True Positive Rate")
ax.set_xlim(0.0, 1.0)
ax.set_ylim(0.0, 1.01)
ax.grid(True, alpha=0.3)

# Legend μέσα, κάτω αριστερά και λίγο πιο “γεμάτο”
ax.legend(loc="lower right", bbox_to_anchor=(0.98, 0.02),
          frameon=True, fancybox=True, framealpha=0.95,
          borderpad=0.8, labelspacing=0.6, handlelength=3.0)


fig.tight_layout()
fig.savefig("xgb_roc_curves.png", dpi=300, bbox_inches="tight")
fig.savefig("xgb_roc_curves.pdf", bbox_inches="tight")
plt.show()

from xgboost import plot_importance
import matplotlib as mpl
import matplotlib.pyplot as plt

# Pick your fitted model
try:
    model = best
except NameError:
    model = clf

# Fonts: Times New Roman, 19pt
mpl.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman", "Times", "DejaVu Serif"],
    "axes.titlesize": 18,
    "axes.labelsize": 18,
    "xtick.labelsize": 18,
    "ytick.labelsize": 18,
    "legend.fontsize": 18,
    "pdf.fonttype": 42,
    "ps.fonttype": 42
})

fig, ax = plt.subplots(figsize=(11, 6.5), dpi=300)

plot_importance(
    model, ax=ax,
    importance_type="weight",
    show_values=True, height=0.8, grid=True
)

ax.set_xlabel("Importance score")
ax.set_ylabel("Features")
ax.set_title("")           # no title
ax.set_xlim(left=0)

# f0,f1,... -> F0,F1,...
yt = ax.get_yticks()
ylabs = [lab.get_text().upper() for lab in ax.get_yticklabels()]
ax.set_yticks(yt)
ax.set_yticklabels(ylabs, fontsize=18)

# numbers on bars -> 19pt
for t in ax.texts:
    t.set_fontsize(18)

# give a bit more room on the right so numbers don't get clipped
try:
    vals = [float(t.get_text()) for t in ax.texts]
    if vals:
        ax.set_xlim(ax.get_xlim()[0], max(vals) * 1.08)
except ValueError:
    pass

fig.tight_layout()
fig.savefig("xgb_feature_importance.png", dpi=300, bbox_inches="tight")
fig.savefig("xgb_feature_importance.pdf", bbox_inches="tight")
plt.show()